{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn is a python library for machine learning.\n",
    "\n",
    "Some things you can do with scikit-learn: http://scikit-learn.org/stable/\n",
    "<img src=\"scikit-learn.png\" width=\"800\">\n",
    "\n",
    "This demo is a summarized version of:\n",
    "https://github.com/amueller/scipy-2016-sklearn/blob/master/notebooks/10%20Case%20Study%20-%20Titanic%20Survival.ipynb\n",
    "\n",
    "\n",
    "\n",
    "In this demo we'll see:\n",
    "1. How to load data from different sources.\n",
    "1. How to do apply some data preprocessing using scikit-learn and Pandas.\n",
    "2. How to use scikit-learn for cross-validation\n",
    "2. How to run all the algorithms we've seen in class (decision tree, perceptron, SVM) with scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Installed Datsets\n",
    "\n",
    "Scikit learn has some pre-installed datasets: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "\n",
    "We're going to check out the \"Iris\" dataset. More information on the Iris dataset is available here: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DESCR', 'target', 'data', 'feature_names', 'target_names'])\n",
      "Number of samples: 150\n",
      "Number of features: 4\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[ 5.1  3.5  1.4  0.2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.keys())\n",
    "#You can check out the description of the dataset using the following command\n",
    "#print(iris.DESCR)\n",
    "\n",
    "n_samples, n_features = iris.data.shape\n",
    "print('Number of samples:', n_samples)\n",
    "print('Number of features:', n_features)\n",
    "# the sepal length, sepal width, petal length and petal width of the first sample (first flower)\n",
    "print('Features:', iris.feature_names)\n",
    "print(iris.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the features: (150, 4)\n",
      "Shape of the labels: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the features:\", iris.data.shape)\n",
    "print(\"Shape of the labels:\", iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# all of the labels\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a scatter plot of the data to get an idea of how it looks. For this we'll use python library, Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ce86c7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_index = 3\n",
    "y_index = 0\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for label, color in zip(range(len(iris.target_names)), colors):\n",
    "    plt.scatter(iris.data[iris.target==label, x_index], \n",
    "                iris.data[iris.target==label, y_index],\n",
    "                label=iris.target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading your own dataset\n",
    "There are different places where you can find data sets like Kaggle, https://archive.ics.uci.edu/ml/datasets.html.\n",
    "\n",
    "Here, we'll be using the titanic dataset. The description can be found here: https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
      "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#loading the datset from .csv file\n",
    "titanic = pd.read_csv(os.path.join('data', 'titanic.csv'))\n",
    "\n",
    "#print columns\n",
    "print(titanic.columns)\n",
    "\n",
    "#labels are stored in column survived. Fetching labels.\n",
    "labels = titanic.survived.values\n",
    "\n",
    "#fetch the columns that we'll be using for our models\n",
    "data = titanic[['pclass', 'sex', 'sibsp', 'parch', 'embarked']]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scikit-learn with real world data: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning\n",
    "Binning is a technique which is used to convert continuous values to discrete values for the ease of classification.\n",
    "\n",
    "If regression is being used, continuous values can be used directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "0    29.0000\n",
      "1     0.9167\n",
      "2     2.0000\n",
      "3    30.0000\n",
      "4    25.0000\n",
      "Name: age, dtype: float64\n",
      "\n",
      "fare\n",
      "0    211.3375\n",
      "1    151.5500\n",
      "2    151.5500\n",
      "3    151.5500\n",
      "4    151.5500\n",
      "Name: fare, dtype: float64\n",
      "\n",
      "property | Age | Fare\n",
      "min 0.1667 0.0\n",
      "max 80.0 512.3292\n",
      "median 28.0 14.4542\n",
      "mean 29.8811345124 33.2954792813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at ages and fares\n",
    "print('age')\n",
    "print(titanic['age'].head(5))\n",
    "print()\n",
    "print('fare')\n",
    "print(titanic['fare'].head(5))\n",
    "print()\n",
    "\n",
    "#lets look at min, max, median and mean for age and fare. This will help us in deciding the bins\n",
    "print('property | Age | Fare')\n",
    "print('min', titanic['age'].min(), titanic['fare'].min())\n",
    "print('max', titanic['age'].max(), titanic['fare'].max())\n",
    "print('median', titanic['age'].median(), titanic['fare'].median())\n",
    "print('mean', titanic['age'].mean(), titanic['fare'].mean())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Softwares\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>young</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>young</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>young</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex  sibsp  parch embarked    age  fare\n",
       "0       1  female      0      0        S  adult  high\n",
       "1       1    male      1      2        S  young  high\n",
       "2       1  female      1      2        S  young  high\n",
       "3       1    male      1      2        S  adult  high\n",
       "4       1  female      1      2        S  young  high"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create bins for age and fare\n",
    "bins_age = [0, 25, 60,  100]\n",
    "bins_fare = [0, 25, 100, 1000]\n",
    "\n",
    "age_groups = ['young', 'adult', 'senior']\n",
    "fare_groups = ['low', 'medium', 'high']\n",
    "\n",
    "data['age'] = pd.cut(titanic['age'], bins_age, labels=age_groups)\n",
    "data['fare'] = pd.cut(titanic['fare'], bins_fare, labels=fare_groups)\n",
    "\n",
    "#remove original columns\n",
    "# del data['age']\n",
    "# del data['fare']\n",
    "\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical values to Numerical values\n",
    "\n",
    "Here we will be converting categorical values like Male/Female to numerical values like 1/2 for easier processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "    pclass  sex  sibsp  parch embarked     age    fare\n",
      "0        1    0      0      0        S   adult    high\n",
      "1        1    1      1      2        S   young    high\n",
      "2        1    0      1      2        S   young    high\n",
      "3        1    1      1      2        S   adult    high\n",
      "4        1    0      1      2        S   young    high\n",
      "5        1    1      0      0        S   adult  medium\n",
      "6        1    0      1      0        S  senior  medium\n",
      "7        1    1      0      0        S   adult     NaN\n",
      "8        1    0      2      0        S   adult  medium\n",
      "9        1    1      0      0        C  senior  medium\n",
      "10       1    1      1      0        C   adult    high\n",
      "11       1    0      1      0        C   young    high\n",
      "12       1    0      0      0        C   young  medium\n",
      "13       1    0      0      0        S   adult  medium\n",
      "14       1    1      0      0        S  senior  medium\n",
      "15       1    1      0      0        S     NaN  medium\n",
      "16       1    1      0      1        C   young    high\n",
      "17       1    0      0      1        C   adult    high\n",
      "18       1    0      0      0        C   adult  medium\n",
      "19       1    1      0      0        C   adult  medium\n",
      "20       1    1      1      1        S   adult  medium\n",
      "21       1    0      1      1        S   adult  medium\n",
      "22       1    1      0      0        C   adult  medium\n",
      "23       1    0      0      0        C   adult    high\n",
      "24       1    0      0      0        S   adult    high\n",
      "    pclass  sex  sibsp  parch  embarked     age    fare\n",
      "0        1    0      0      0         0   adult    high\n",
      "1        1    1      1      2         0   young    high\n",
      "2        1    0      1      2         0   young    high\n",
      "3        1    1      1      2         0   adult    high\n",
      "4        1    0      1      2         0   young    high\n",
      "5        1    1      0      0         0   adult  medium\n",
      "6        1    0      1      0         0  senior  medium\n",
      "7        1    1      0      0         0   adult     NaN\n",
      "8        1    0      2      0         0   adult  medium\n",
      "9        1    1      0      0         1  senior  medium\n",
      "10       1    1      1      0         1   adult    high\n",
      "11       1    0      1      0         1   young    high\n",
      "12       1    0      0      0         1   young  medium\n",
      "13       1    0      0      0         0   adult  medium\n",
      "14       1    1      0      0         0  senior  medium\n",
      "15       1    1      0      0         0     NaN  medium\n",
      "16       1    1      0      1         1   young    high\n",
      "17       1    0      0      1         1   adult    high\n",
      "18       1    0      0      0         1   adult  medium\n",
      "19       1    1      0      0         1   adult  medium\n",
      "20       1    1      1      1         0   adult  medium\n",
      "21       1    0      1      1         0   adult  medium\n",
      "22       1    1      0      0         1   adult  medium\n",
      "23       1    0      0      0         1   adult    high\n",
      "24       1    0      0      0         0   adult    high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Softwares\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "print(type(data['sex'][0]))\n",
    "data['sex'] = le.fit_transform(data['sex'])\n",
    "le = LabelEncoder()\n",
    "print(data.head(25))\n",
    "# data['embarked'] = le.fit_transform(data['embarked'])\n",
    "data['embarked'] = data['embarked'].factorize()[0]\n",
    "# data['embarked'] = le.fit_transform(data['embarked'])\n",
    "\n",
    "print(data.head(25))\n",
    "# list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Softwares\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pclass  sex  sibsp  parch  embarked  age  fare\n",
       "0        1    0      0      0         0    0     0\n",
       "1        1    1      1      2         0    1     0\n",
       "2        1    0      1      2         0    1     0\n",
       "3        1    1      1      2         0    0     0\n",
       "4        1    0      1      2         0    1     0\n",
       "5        1    1      0      0         0    0     1\n",
       "6        1    0      1      0         0    2     1\n",
       "7        1    1      0      0         0    0    -1\n",
       "8        1    0      2      0         0    0     1\n",
       "9        1    1      0      0         1    2     1\n",
       "10       1    1      1      0         1    0     0\n",
       "11       1    0      1      0         1    1     0\n",
       "12       1    0      0      0         1    1     1\n",
       "13       1    0      0      0         0    0     1\n",
       "14       1    1      0      0         0    2     1\n",
       "15       1    1      0      0         0   -1     1\n",
       "16       1    1      0      1         1    1     0\n",
       "17       1    0      0      1         1    0     0\n",
       "18       1    0      0      0         1    0     1\n",
       "19       1    1      0      0         1    0     1\n",
       "20       1    1      1      1         0    0     1\n",
       "21       1    0      1      1         0    0     1\n",
       "22       1    1      0      0         1    0     1\n",
       "23       1    0      0      0         1    0     0\n",
       "24       1    0      0      0         0    0     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'] = data['age'].factorize()[0]\n",
    "# data['age'] = le.fit_transform(data['age'])\n",
    "data['fare'] = data['fare'].factorize()[0]\n",
    "# data['fare'] = le.fit_transform(data['fare'])\n",
    "\n",
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pclass  sex  sibsp  parch  embarked  age  fare\n",
      "0          1    0      0      0       0.0  0.0   0.0\n",
      "1          1    1      1      2       0.0  1.0   0.0\n",
      "2          1    0      1      2       0.0  1.0   0.0\n",
      "3          1    1      1      2       0.0  0.0   0.0\n",
      "4          1    0      1      2       0.0  1.0   0.0\n",
      "5          1    1      0      0       0.0  0.0   1.0\n",
      "6          1    0      1      0       0.0  2.0   1.0\n",
      "7          1    1      0      0       0.0  0.0   NaN\n",
      "8          1    0      2      0       0.0  0.0   1.0\n",
      "9          1    1      0      0       1.0  2.0   1.0\n",
      "10         1    1      1      0       1.0  0.0   0.0\n",
      "11         1    0      1      0       1.0  1.0   0.0\n",
      "12         1    0      0      0       1.0  1.0   1.0\n",
      "13         1    0      0      0       0.0  0.0   1.0\n",
      "14         1    1      0      0       0.0  2.0   1.0\n",
      "15         1    1      0      0       0.0  NaN   1.0\n",
      "16         1    1      0      1       1.0  1.0   0.0\n",
      "17         1    0      0      1       1.0  0.0   0.0\n",
      "18         1    0      0      0       1.0  0.0   1.0\n",
      "19         1    1      0      0       1.0  0.0   1.0\n",
      "20         1    1      1      1       0.0  0.0   1.0\n",
      "21         1    0      1      1       0.0  0.0   1.0\n",
      "22         1    1      0      0       1.0  0.0   1.0\n",
      "23         1    0      0      0       1.0  0.0   0.0\n",
      "24         1    0      0      0       0.0  0.0   0.0\n",
      "25         1    1      0      0       1.0  1.0   1.0\n",
      "26         1    1      1      0       1.0  1.0   1.0\n",
      "27         1    0      1      0       1.0  1.0   1.0\n",
      "28         1    0      0      0       0.0  0.0   0.0\n",
      "29         1    1      0      0       0.0  0.0   1.0\n",
      "...      ...  ...    ...    ...       ...  ...   ...\n",
      "1279       3    0      0      0       0.0  1.0   2.0\n",
      "1280       3    1      0      0       0.0  1.0   2.0\n",
      "1281       3    1      0      0       0.0  1.0   2.0\n",
      "1282       3    1      0      0       0.0  NaN   2.0\n",
      "1283       3    1      0      0       0.0  NaN   2.0\n",
      "1284       3    1      0      0       0.0  NaN   2.0\n",
      "1285       3    1      0      0       0.0  0.0   2.0\n",
      "1286       3    0      0      0       1.0  0.0   2.0\n",
      "1287       3    1      0      0       0.0  0.0   2.0\n",
      "1288       3    1      1      0       0.0  1.0   2.0\n",
      "1289       3    1      1      0       0.0  1.0   2.0\n",
      "1290       3    0      1      0       0.0  0.0   2.0\n",
      "1291       3    1      0      0       0.0  NaN   2.0\n",
      "1292       3    1      0      0       0.0  NaN   2.0\n",
      "1293       3    1      0      0       0.0  NaN   2.0\n",
      "1294       3    1      0      0       0.0  0.0   2.0\n",
      "1295       3    1      0      0       0.0  1.0   2.0\n",
      "1296       3    1      0      0       0.0  0.0   2.0\n",
      "1297       3    1      0      0       0.0  NaN   2.0\n",
      "1298       3    1      0      0       0.0  0.0   2.0\n",
      "1299       3    1      1      0       1.0  0.0   2.0\n",
      "1300       3    0      1      0       1.0  1.0   2.0\n",
      "1301       3    1      0      0       1.0  0.0   2.0\n",
      "1302       3    1      0      0       1.0  NaN   2.0\n",
      "1303       3    1      0      0       1.0  NaN   2.0\n",
      "1304       3    0      1      0       1.0  1.0   2.0\n",
      "1305       3    0      1      0       1.0  NaN   2.0\n",
      "1306       3    1      0      0       1.0  0.0   2.0\n",
      "1307       3    1      0      0       1.0  0.0   2.0\n",
      "1308       3    1      0      0       0.0  0.0   2.0\n",
      "\n",
      "[1309 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex  sibsp  parch  embarked  age  fare\n",
       "0          1    0      0      0       0.0  0.0   0.0\n",
       "1          1    1      1      2       0.0  1.0   0.0\n",
       "2          1    0      1      2       0.0  1.0   0.0\n",
       "3          1    1      1      2       0.0  0.0   0.0\n",
       "4          1    0      1      2       0.0  1.0   0.0\n",
       "5          1    1      0      0       0.0  0.0   1.0\n",
       "6          1    0      1      0       0.0  2.0   1.0\n",
       "7          1    1      0      0       0.0  0.0   2.0\n",
       "8          1    0      2      0       0.0  0.0   1.0\n",
       "9          1    1      0      0       1.0  2.0   1.0\n",
       "10         1    1      1      0       1.0  0.0   0.0\n",
       "11         1    0      1      0       1.0  1.0   0.0\n",
       "12         1    0      0      0       1.0  1.0   1.0\n",
       "13         1    0      0      0       0.0  0.0   1.0\n",
       "14         1    1      0      0       0.0  2.0   1.0\n",
       "15         1    1      0      0       0.0  0.0   1.0\n",
       "16         1    1      0      1       1.0  1.0   0.0\n",
       "17         1    0      0      1       1.0  0.0   0.0\n",
       "18         1    0      0      0       1.0  0.0   1.0\n",
       "19         1    1      0      0       1.0  0.0   1.0\n",
       "20         1    1      1      1       0.0  0.0   1.0\n",
       "21         1    0      1      1       0.0  0.0   1.0\n",
       "22         1    1      0      0       1.0  0.0   1.0\n",
       "23         1    0      0      0       1.0  0.0   0.0\n",
       "24         1    0      0      0       0.0  0.0   0.0\n",
       "25         1    1      0      0       1.0  1.0   1.0\n",
       "26         1    1      1      0       1.0  1.0   1.0\n",
       "27         1    0      1      0       1.0  1.0   1.0\n",
       "28         1    0      0      0       0.0  0.0   0.0\n",
       "29         1    1      0      0       0.0  0.0   1.0\n",
       "...      ...  ...    ...    ...       ...  ...   ...\n",
       "1279       3    0      0      0       0.0  1.0   2.0\n",
       "1280       3    1      0      0       0.0  1.0   2.0\n",
       "1281       3    1      0      0       0.0  1.0   2.0\n",
       "1282       3    1      0      0       0.0  0.0   2.0\n",
       "1283       3    1      0      0       0.0  0.0   2.0\n",
       "1284       3    1      0      0       0.0  0.0   2.0\n",
       "1285       3    1      0      0       0.0  0.0   2.0\n",
       "1286       3    0      0      0       1.0  0.0   2.0\n",
       "1287       3    1      0      0       0.0  0.0   2.0\n",
       "1288       3    1      1      0       0.0  1.0   2.0\n",
       "1289       3    1      1      0       0.0  1.0   2.0\n",
       "1290       3    0      1      0       0.0  0.0   2.0\n",
       "1291       3    1      0      0       0.0  0.0   2.0\n",
       "1292       3    1      0      0       0.0  0.0   2.0\n",
       "1293       3    1      0      0       0.0  0.0   2.0\n",
       "1294       3    1      0      0       0.0  0.0   2.0\n",
       "1295       3    1      0      0       0.0  1.0   2.0\n",
       "1296       3    1      0      0       0.0  0.0   2.0\n",
       "1297       3    1      0      0       0.0  0.0   2.0\n",
       "1298       3    1      0      0       0.0  0.0   2.0\n",
       "1299       3    1      1      0       1.0  0.0   2.0\n",
       "1300       3    0      1      0       1.0  1.0   2.0\n",
       "1301       3    1      0      0       1.0  0.0   2.0\n",
       "1302       3    1      0      0       1.0  0.0   2.0\n",
       "1303       3    1      0      0       1.0  0.0   2.0\n",
       "1304       3    0      1      0       1.0  1.0   2.0\n",
       "1305       3    0      1      0       1.0  0.0   2.0\n",
       "1306       3    1      0      0       1.0  0.0   2.0\n",
       "1307       3    1      0      0       1.0  0.0   2.0\n",
       "1308       3    1      0      0       0.0  0.0   2.0\n",
       "\n",
       "[1309 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "# imp = Imputer(strategy=\"median\") # can supply different strategies\n",
    "# imp.fit(data)\n",
    "# data = imp.transform(data)\n",
    "\n",
    "\n",
    "# print(\"All the training data\", data)\n",
    "# print(\"Age\", data[:,1])\n",
    "# data = pd.DataFrame(data)\n",
    "# type(data)\n",
    "# data\n",
    "data = data.replace('-1', np.nan)\n",
    "print(data)\n",
    "data = data.fillna(data.median())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical Values to Boolean Values (Binary Values)\n",
    "We will be using one-hot-encoding to convert categorical features to binary features.\n",
    "\n",
    "####What is one-hot-encoding?\n",
    "\n",
    "When a column has categorical values, it is hard for the machine learning algorithm to train  upon. To make it more suitable for the ML algorithms, we convert each category for that column to a boolean column. Only one of the columns can take a value of one for a single sample. Hence, it is called as one hot encoding. \n",
    "\n",
    "(eg) Suppose you have flower feature which can take values daffodil, lily, and rose. One hot encoding converts flower feature to three features, is_daffodil, is_lily, and is_rose which all are binary.\n",
    "\n",
    "We will be using pandas' get_dummies() function which is equivalent to scikit-learn OneHotEncoder.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "\n",
    "Refer: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  1.  0.  0.]\n",
      " [ 1.  0.  0. ...,  1.  0.  0.]\n",
      " [ 1.  0.  0. ...,  1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1. ...,  0.  0.  1.]\n",
      " [ 0.  0.  1. ...,  0.  0.  1.]\n",
      " [ 0.  0.  1. ...,  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#to convert all categorical columns to boolean columns\n",
    "# data = pd.get_dummies(data)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc_data = enc.fit_transform(data).toarray()\n",
    "\n",
    "#you can also select the columns to convert. I don't know why you would do that though!\n",
    "# data = pd.get_dummies(data, columns=[ 'sex', 'embarked', 'age', 'fare'])\n",
    "print(enc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the original age data is 0.38884644767\n",
      "The std  of the original age data is 0.536922051228\n",
      "\n",
      "The mean of the transformed age data is 2.71406698151e-17\n",
      "The std  of the transformed age data is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "processed_age_data = preprocessing.scale(data['age'])\n",
    "\n",
    "print(\"The mean of the original age data is\", data['age'].mean(axis=0))\n",
    "print(\"The std  of the original age data is\", data['age'].std(axis=0))\n",
    "print()\n",
    "\n",
    "print(\"The mean of the transformed age data is\", processed_age_data.mean(axis=0))\n",
    "print(\"The std  of the transformed age data is\", processed_age_data.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Test-Train Split\n",
    "Still the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=0)\n",
    "\n",
    "enc_train_data, enc_test_data, enc_train_labels, enc_test_labels = train_test_split(enc_data, labels, random_state=0)\n",
    "#Again fill in missing values\n",
    "# imp = Imputer()\n",
    "# imp.fit(train_data)\n",
    "# train_data_finite = imp.transform(train_data)\n",
    "# test_data_finite = imp.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms we know in scikit-learn\n",
    "### Most Common Label Classifier\n",
    "\n",
    "Scikit learn calls this a \"dummy\" classifier. Easy \"baseline\" for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.634146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier('most_frequent')\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Prediction accuracy: %f\" % clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "More info at: http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24091386 -1.01926197 -0.10676417 -0.00748992  0.09276051  0.0326393\n",
      "  -0.06525052]]\n",
      "[ 1.08556847]\n",
      "0.786585365854\n",
      "[[ 0.11105987 -0.11283395 -0.32846026  0.33539996 -0.66563429  0.54656211\n",
      "   0.48331344  0.41465697  0.16695632 -0.54638545 -0.64570403 -0.74963369\n",
      "   0.31757107  0.53572553  0.42170866  0.32490162 -0.07809115 -0.64545968\n",
      "  -0.60329543 -0.60329496 -0.222609   -0.03532068 -0.07230466  0.01468183\n",
      "   0.13990158 -0.48481775 -0.10131836 -0.0471501  -0.18176588]]\n",
      "[-0.33023434]\n",
      "0.792682926829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=4000)\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(test_data, test_labels))\n",
    "\n",
    "\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "LinearSVC()\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(enc_test_data, enc_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validating SVM\n",
    "\n",
    "We will be cross validating for parameter C. As you might remeber from class, C is the penalty parameter of the error formula.\n",
    "\n",
    "From http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.679 (+/-0.023) for {'C': 0.001}\n",
      "0.795 (+/-0.028) for {'C': 0.01}\n",
      "0.795 (+/-0.028) for {'C': 0.01}\n",
      "0.792 (+/-0.028) for {'C': 1}\n",
      "0.789 (+/-0.023) for {'C': 10}\n",
      "0.739 (+/-0.077) for {'C': 100}\n",
      "0.681 (+/-0.306) for {'C': 1000}\n",
      "0.608 (+/-0.319) for {'C': 5000}\n",
      "\n",
      "[[-0.18379599 -0.76373116 -0.06978269  0.03984783  0.1292801   0.05283752\n",
      "  -0.00391419]]\n",
      "[ 0.61032088]\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=4000, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.786585365854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [1e-3, 1e-2, 1e-2, 1, 10, 100, 1000, 5000]}]\n",
    "\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(LinearSVC(), tuned_parameters, cv=5,\n",
    "                   scoring='accuracy')\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "\n",
    "clf = LinearSVC(random_state=4000, C=clf.best_params_['C'])\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6. -13.  -1.  -1.   2.   0.  -3.]]\n",
      "[ 12.]\n",
      "0.725609756098\n",
      "[[ 3. -1. -3.  1. -2.  2.  1.  4.  1. -4. -2. -3.  0.  3.  2.  3. -2. -4.\n",
      "  -2. -1. -3.  2.  0. -1.  2. -2.  0.  2. -3.]]\n",
      "[-1.]\n",
      "0.762195121951\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(random_state=2000)\n",
    "clf.fit(train_data, train_labels)\n",
    "Perceptron()\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(test_data, test_labels))\n",
    "\n",
    "\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "Perceptron()\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(enc_test_data, enc_test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/tree.html\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "#for windows, uncomment the following and replace with path of you local Graphviz.38/bin. Include path of bin and not python lib\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.795731707317\n",
      "The depth of this tree is 11\n",
      "Accuracy 0.801829268293\n",
      "The depth of this tree is 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'graphs/dt_gini_enc.pdf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(train_data, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini')\n",
    "\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(enc_test_data, enc_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try using a different criterion to build the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.795731707317\n",
      "The depth of this tree is 11\n",
      "Accuracy 0.801829268293\n",
      "The depth of this tree is 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'graphs/dt_entropy_enc.pdf'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(train_data, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_entropy')\n",
    "\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(enc_test_data, enc_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_entropy_enc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try limiting the depth and visualize our tree...\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.77743902439\n",
      "The depth of this tree is 1\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"256pt\" height=\"165pt\"\r\n",
       " viewBox=\"0.00 0.00 255.50 165.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 161)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-161 251.5,-161 251.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"180.5,-157 62.5,-157 62.5,-89 180.5,-89 180.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[1] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.4746</text>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 981</text>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [601, 380]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111,-53 0,-53 0,-0 111,-0 111,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.392</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 355</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [95, 260]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.4164,-88.9485C92.219,-80.0749 85.5072,-70.4648 79.2731,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.0702,-59.4311 73.4748,-53.2367 76.3313,-63.4392 82.0702,-59.4311\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"69.104\" y=\"-74.1516\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"247.5,-53 129.5,-53 129.5,-0 247.5,-0 247.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"188.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.3099</text>\r\n",
       "<text text-anchor=\"middle\" x=\"188.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 626</text>\r\n",
       "<text text-anchor=\"middle\" x=\"188.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [506, 120]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.933,-88.9485C151.225,-80.0749 158.038,-70.4648 164.367,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.324,-63.4188 170.253,-53.2367 161.614,-59.3701 167.324,-63.4188\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"174.449\" y=\"-74.182\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x21ceacca780>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=1)\n",
    "clf.fit(train_data, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini_limit')\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.77743902439\n",
      "The depth of this tree is 1\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"256pt\" height=\"165pt\"\r\n",
       " viewBox=\"0.00 0.00 255.50 165.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 161)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-161 251.5,-161 251.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"180.5,-157 62.5,-157 62.5,-89 180.5,-89 180.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[4] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.4746</text>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 981</text>\r\n",
       "<text text-anchor=\"middle\" x=\"121.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [601, 380]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111,-53 0,-53 0,-0 111,-0 111,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.392</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 355</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [95, 260]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.4164,-88.9485C92.219,-80.0749 85.5072,-70.4648 79.2731,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.0702,-59.4311 73.4748,-53.2367 76.3313,-63.4392 82.0702,-59.4311\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"69.104\" y=\"-74.1516\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"247.5,-53 129.5,-53 129.5,-0 247.5,-0 247.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"188.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.3099</text>\r\n",
       "<text text-anchor=\"middle\" x=\"188.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 626</text>\r\n",
       "<text text-anchor=\"middle\" x=\"188.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [506, 120]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.933,-88.9485C151.225,-80.0749 158.038,-70.4648 164.367,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.324,-63.4188 170.253,-53.2367 161.614,-59.3701 167.324,-63.4188\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"174.449\" y=\"-74.182\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x21ceacca630>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.tree_.__getstate__()\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(enc_test_data, enc_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini_limit_enc')\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Here we'll be training a random forest. Try modifying the parameters and see how it affects the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16405715  0.51632839  0.07169227  0.07324637  0.04818935  0.0360459\n",
      "  0.09044058]\n",
      "0.817073170732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=6, random_state=0, n_estimators=35, criterion='gini')\n",
    "clf.fit(train_data, train_labels)\n",
    "print(clf.feature_importances_)\n",
    "print(clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other algorithms we haven't covered in class\n",
    "\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Adaboost\n",
    "- Multiclass classifiers\n",
    "- K Nearest Neighbors\n",
    "- Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links!\n",
    "- Scikit learn official page: http://scikit-learn.org/stable/index.html\n",
    "\n",
    "- Pandas official page: http://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "- lots of scikit demos: https://github.com/amueller/scipy-2016-sklearn/tree/master/notebooks\n",
    "\n",
    "- svm documentation: http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "- decision tree documentation: http://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "- perceptron documentation: http://scikit-learn.org/stable/modules/linear_model.html#perceptron\n",
    "\n",
    "- graphing trees: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "- cross-validation parameter search documentation: http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
